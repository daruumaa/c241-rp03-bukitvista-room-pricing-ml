{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "qjmfM8iz-sTk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from xgboost import XGBRegressor\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datasets required to run this script:\n",
        "- Feature engineered base price data\n"
      ],
      "metadata": {
        "id": "EiW_xbwiAanA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility Functions"
      ],
      "metadata": {
        "id": "pIYJs4Yt-7L-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data preprocessing utilities"
      ],
      "metadata": {
        "id": "jIFJNTR_ABVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Onehot encode values with auxillary document\n",
        "def custom_one_hot_encode(df, all_categories, column_name):\n",
        "    \"\"\"\n",
        "    One-hot encode a specific column in a DataFrame, including all possible categories.\n",
        "\n",
        "    Parameters:\n",
        "    df (pd.DataFrame): The DataFrame to be one-hot encoded.\n",
        "    all_categories (pd.Series): A Series containing all possible categorical values.\n",
        "    column_name (str): The name of the column to be one-hot encoded.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: The DataFrame with one-hot encoded columns.\n",
        "    \"\"\"\n",
        "    all_categories = all_categories.unique()\n",
        "\n",
        "    # One-hot encode the column with all possible categories\n",
        "    one_hot_df = pd.get_dummies(df[column_name], prefix=column_name)\n",
        "\n",
        "    # Create a DataFrame with all possible categories set to 0\n",
        "    all_categories_df = pd.DataFrame(columns=[f\"{column_name}_{category}\" for category in all_categories])\n",
        "    all_categories_df = all_categories_df.reindex(columns=all_categories_df.columns, fill_value=0)\n",
        "\n",
        "    # Concatenate the one-hot encoded df with the all_categories_df\n",
        "    final_df = pd.concat([one_hot_df, all_categories_df], axis=1)\n",
        "\n",
        "    # Ensure the final DataFrame has all columns from all_categories_df\n",
        "    final_df = final_df.reindex(columns=all_categories_df.columns, fill_value=0)\n",
        "\n",
        "    # Drop the original categorical column from the original DataFrame and concatenate with the final one-hot encoded DataFrame\n",
        "    df = df.drop(columns=[column_name])\n",
        "    df = pd.concat([df, final_df], axis=1)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "lSL7mkvE-8gw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def drop_columns(df, columns_to_drop):\n",
        "    \"\"\"\n",
        "    Drop specified columns from a DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    df (pd.DataFrame): The DataFrame from which columns should be dropped.\n",
        "    columns_to_drop (list): A list of column names to be dropped.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: The DataFrame with specified columns dropped.\n",
        "    \"\"\"\n",
        "    # Drop the specified columns\n",
        "    df_dropped = df.drop(columns=columns_to_drop)\n",
        "    return df_dropped"
      ],
      "metadata": {
        "id": "x9jNmA7r_x5B"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rYg0AoahEN9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Utilities"
      ],
      "metadata": {
        "id": "EbARqPamAEV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def TrainFitPredict(model,iterations,X, y,X_test ,y_test): #Takes in split dataset, returns test scores, train history, and the model itself.\n",
        "  model.fit(X,y)\n",
        "  test_score = np.zeros((iterations,), dtype=np.float64)\n",
        "  for i, y_pred in enumerate(model.staged_predict(X_test)):\n",
        "    test_score[i] = mean_absolute_error(y_test, y_pred)\n",
        "  return test_score, model.train_score_, model"
      ],
      "metadata": {
        "id": "282zW9LVAF4P"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GetModelMAE(trained_model, X_test, y_test):\n",
        "  mae = mean_absolute_error(y_test, trained_model.predict(X_test))\n",
        "  return mae"
      ],
      "metadata": {
        "id": "0k4hMZunAW6g"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def PlotPerformance(test_scores, train_scores): #plots training + test by receiving test and training scores provided by TrainFitPredict\n",
        "  fig = plt.figure(figsize=(6, 6))\n",
        "  plt.subplot(1, 1, 1)\n",
        "  plt.title(\"MSE\")\n",
        "  plt.plot(\n",
        "      np.arange(len(train_scores)) + 1,\n",
        "      train_scores,\n",
        "      \"b-\",\n",
        "      label=\"Training Set Deviance\",\n",
        "  )\n",
        "  plt.plot(\n",
        "      np.arange(len(test_scores)) + 1, test_scores, \"r-\", label=\"Test Set Deviance\"\n",
        "  )\n",
        "  plt.legend(loc=\"upper right\")\n",
        "  plt.xlabel(\"Boosting Iterations\")\n",
        "  plt.ylabel(\"Deviance\")\n",
        "  fig.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "HYyHbMyuARuG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Data"
      ],
      "metadata": {
        "id": "KRtDptdW-4bH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/FE_RoomBasePrice.csv')"
      ],
      "metadata": {
        "id": "qMT_7K7y-5T3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columnsToDropBeforeTraining = ['Unnamed: 0.1','Unnamed: 0', 'room_id']"
      ],
      "metadata": {
        "id": "xiUN_qyjA5R3"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Obtain target label"
      ],
      "metadata": {
        "id": "mmLyPmZudK6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "average_baseline_price = data['average_baseline_price']"
      ],
      "metadata": {
        "id": "fO15mYUVdIYs"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Labels ready for training"
      ],
      "metadata": {
        "id": "f9XwxCh4erCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ready_cols = ['ac', 'balcony', 'beachfront', 'breakfast', 'building_staff',\n",
        "                             'cable_tv', 'essentials', 'garden', 'gym', 'hair_dryer',\n",
        "                             'hanger', 'heating', 'hot_water', 'kitchen', 'linens',\n",
        "                             'lock', 'luggage_drop_off', 'parking', 'pool',\n",
        "                             'private_entrance', 'shampoo', 'tv', 'washer', 'wifi',\n",
        "                             'workspace']\n",
        "ready_cols_df = pd.DataFrame(data, columns=ready_cols)"
      ],
      "metadata": {
        "id": "WLf60EkWeuf7"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess Categoricals\n",
        "One hot encode all categoricals"
      ],
      "metadata": {
        "id": "q0hpIQpZKi4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_cols = ['unit_type_name', 'property_design', 'property_type','area_name']\n",
        "onehot_encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
        "categorical_encoded = onehot_encoder.fit_transform(data[categorical_cols])\n",
        "\n",
        "categorical_encoded_df = pd.DataFrame(categorical_encoded, columns=onehot_encoder.get_feature_names_out(categorical_cols))"
      ],
      "metadata": {
        "id": "_W5JX7eKKvm_"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess numericals\n",
        "Either normalize them, or not do anything at all."
      ],
      "metadata": {
        "id": "ILx0GyhJKl6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_cols = ['bedroom','bathroom','beds','capacity','lat','lng','distance_to_coastline','area_distance_to_airport','average_baseline_price', 'total_fas','ratio_bedroom_bathroom','ratio_bedroom_cap',\n",
        "                  'avg_price_distance_to_coast', 'avg_price_distance_to_airport', 'avg_price_bedroom','avg_price_beds','avg_price_bathroom','avg_price_total_fas']\n",
        "scaler = StandardScaler()\n",
        "numerical_scaled = scaler.fit_transform(data[numerical_cols])\n",
        "\n",
        "numerical_scaled_df = pd.DataFrame(numerical_scaled, columns=numerical_cols)\n"
      ],
      "metadata": {
        "id": "-OkMFl4bKvYI"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compiling Preprocessed Data"
      ],
      "metadata": {
        "id": "dUjlzaxzfzY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_final = pd.concat([numerical_scaled_df, categorical_encoded_df,ready_cols_df, average_baseline_price.reset_index(drop=True)], axis=1)"
      ],
      "metadata": {
        "id": "uzuqAvGQf1WL"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training"
      ],
      "metadata": {
        "id": "ZVW2jWglKuaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_final.drop(columns=['average_baseline_price'])\n",
        "y = df_final['average_baseline_price']"
      ],
      "metadata": {
        "id": "CBCKhIQdKneY"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "QPNJRpWfKyCP"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameters"
      ],
      "metadata": {
        "id": "iasxjCcuKzGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_RATIO = 0.25\n",
        "RANDOM_STATE = 123\n",
        "params = {\n",
        "    \"n_estimators\": 10000,\n",
        "    \"max_depth\": 8,\n",
        "    \"min_samples_split\": 5,\n",
        "    \"learning_rate\": 0.1,\n",
        "    \"loss\": \"squared_error\",\n",
        "}"
      ],
      "metadata": {
        "id": "h_LPxndyK0Sw"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR = LinearRegression()\n",
        "DTR = DecisionTreeRegressor(random_state=RANDOM_STATE)\n",
        "RFR = RandomForestRegressor(n_estimators=params['n_estimators'],max_depth=params[\"max_depth\"],random_state=RANDOM_STATE)\n",
        "XGB = XGBRegressor(n_estimators=params['n_estimators'], max_depth=params[\"max_depth\"], learning_rate=params['learning_rate'])\n",
        "ModelsList = [\n",
        "              XGB,\n",
        "              RFR,\n",
        "              DTR,\n",
        "              LR,]\n",
        "modelMAEs = []\n",
        "for model in ModelsList:\n",
        "  model.fit(X_train,y_train)\n",
        "  modelMAEs.append((model.__class__.__name__, GetModelMAE(model, X_test, y_test)))\n",
        "print(modelMAEs)"
      ],
      "metadata": {
        "id": "DL4-tLplK3an",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c8ecdde-282a-424f-f191-488f46a6df57"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('XGBRegressor', 125032.04096152808), ('RandomForestRegressor', 106512.54040518399), ('DecisionTreeRegressor', 105637.92082925077), ('LinearRegression', 3.757578594329328e+17)]\n"
          ]
        }
      ]
    }
  ]
}